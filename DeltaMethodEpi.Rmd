---
title: "Statistical Inference for Functionals in Epidemiology: The Bootstrap and the Delta Method. An Applied and Reproducible Tutorial"
author: "Miguel Angel Luque Fernandez, MA, MPH, MSc, Ph.D"
date: "02/03/2020 \n https://scholar.harvard.edu/malf/home"
output:
  html_notebook:
    code_folding: show
    highlight: default
    number_sections: no
    theme: journal
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  word_document:
    toc: yes
  pdf_document:
     toc: true
     number_sections: true
  html_document:
    toc: yes
font-family: Risque
font-import: http://fonts.googleapis.com/css?family=Risque
csl: references/isme.csl
bibliography: references/bibliography.bib
---

<a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

```{r options, echo=FALSE, eval=FALSE}
options(scipen=999, digits=5, tinytex.verbose = TRUE)
```

# Introduction

The delta method is really a theorem which states that a smooth function of an asymptotically normal estimator is also asymptotically normally distributed. It can also be viewed as a technique for approximating variance of a function of a nonlinear function of a random variable [@Armi2005]. 

In epidemiology we use routinely the delta method to compute the standard error (SE) of the risk difference (RD), the risk ratio (RR), and the odds ratio (OR) [@Agresti2010]. Often in addition to reporting parameters fit by a model, we need to report some marginal transformation of these parameters. The transformation can generate the point estimates of our desired values, but the SE of these point estimates are not so easily calculated. 

For instance, in causal inference we compute the average treatment effect (ATE), namely $\Psi$ as a function of two random variables (i.e., the potential outcomes or counterfactuals E(Y1) and E(Y0)) [@van2006; @van2011]
$$\Psi\,=\,\text{E(Y|A=1,X)} - \text{E(Y|A=0,X)}$$
Using G-computation, these two random variables are derived from the coefficients of the parameters fitted in two different regression models [@robins1986]. Here the Functional Delta Method in addition to the Semiparametric and Empirical Process theory come to help assuming that $\Psi$ is pathwise differentiable and asymptotically linear [@kennedy2016; @kennedy2017]. Note that although the delta method is often appropriate to use with large samples, other methods can be used to estimate standard errors, such as the  bootstrap [@Efron1993; @efron1982].

Essentially, the delta method involves calculating the expansion up to the first order of a Taylor series approximation of a function [@Herberg1962]:

$$f(\hat\theta)-f(\theta)\;\approx\;f'(\theta)(\hat\theta\,-\,\theta)\,+\,\text{Op}(\frac{1}{\sqrt(n)}) \;\;(1).$$

Asymptotically  
$$\text{Op}(\frac{1}{\sqrt(n)}) \rightarrow 0 \;\text{and},$$

$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))\;\;(2).$$ 
Therefore    
1. Asymptotically the mean of $f(\hat\theta)$ can be approximate with the empirical mean of $f(\theta)$ and  
2. The standard error (SE) of $f(\hat\theta)$ can be approximated as $f'(\theta)(var(\theta))$

For the multivariate case we first get the Taylor series approximation of the function using the first two terms of the expansion of the transformation function about the mean of of the random variable. Let $f(\cdot)$ be the transformation function and $\theta$ be the mean vector of random variables $(\text{x}\,=\,(x_1,x_2,…))$. The first two terms of the Taylor expansion are then an approximation for $\hat\theta$,

$$f(\hat\theta) \approx\, f(\theta) \nabla(\theta)^T\,(\hat\theta\,-\,\theta).$$
Where $\nabla \theta$ is the gradient of $\theta$, or a vector of partial derivatives of $\theta$. We can then take the variance of this approximation to estimate the variance of $\theta$ and thus the SE of a transformed parameter. For a random variable X with known variance Var(X), the variance of the transformation of X, $\theta$ is approximated by:

$$Var(\hat\theta)\approx  \nabla\theta^T\text{Cov}(\text{x})\nabla\theta\;\;(3).$$
where Cov(X) is the variance-covariance matrix of X [@ucla].

In summary, for observed data $\text{O}_i$, i = 1, ..., n an asymptotically linear estimator $\hat\Psi$ of an estimand $\Psi$, is an estimator that can be represented as follows: 
$$\hat\Psi\,-\,\Psi\;=\;\frac{1}{n}\sum_{i=1}^n \text{D}(\text{O}_{i})\,+\,\text{Op}(\frac{1}{\sqrt(n)})\;\;(4).$$
Where  
$$\text{D}(\text{O}_{i})=f'(\theta)(\hat\theta\,-\,\theta).$$
In other words, the difference between the estimator and estimand can be represented as the sample mean of a fixed function (the *"Influence function”*) plus a remainder term that must converge to 0 at a rate faster than $\frac{1}{\sqrt{n}}$. The estimated influence function provides an asymptotic variance estimate for the estimator (i.e., we can apply the *Central Limit Theorem* and compute *Wald* type confidence intervals) [@van2011]. 

## Delta Method for the RD, RR, and OR (univariate case)

Using the classical 2 by 2 epidemiological table presenting outcome counts by the levels of a risk factor, we are going to derive the SE for the for the RD, RR and OR using the Delta Method

Risk      | Alive  | Dead         
--------  | ----------- | -----------
Exposed   |$\text{n}_{11}$ = ($\text{p}_{1}$) | $\text{n}_{21}$ = ($\text{p}_{2}$)   
Unexposed |$\text{n}_{12}$ = (1 -$\text{p}_{1}$)| $\text{n}_{22}$ = (1-$\text{p}_{2}$) 
  N       | $\text{N}_{1}$     |   $\text{N}_{2}$     

### Risk Difference (RD)
The risk difference is defined as follows [@Rothman2008]:  

$$\widehat{RD} \,=\, \hat \theta_{1}\,-\,\hat \theta_{2} \,=\, \hat p_{1}\,-\,\hat p_{2}.$$
Assuming that the probability of the event (**p**) can be modelled using a Bernoulli distribution with range $0\;\leq \text{p} \leq\;1$, expectation of p is E(p) = p, and the variance var(p) = p(1-p)/n.   

Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta)).$$
and using for the probability (p) the formula in (4)

$$SE(\widehat{RD})\,=f'(\theta)(var(\theta))\;=\; \sqrt{\frac{p(1-p)}{n}}$$
We have that for the RD the SE is  
$$SE(\widehat{RD})\,=\, \sqrt{\frac{(1-\hat p_{1})}{n_{1}}}\,+\,\sqrt{\frac{(1-\hat p_{2})}{n_{2}}}\,=\,\sqrt{\frac{(1-\hat p_{1})}{n_{1}}\,+\,\frac{(1-\hat p_{2})}{n_{2}}}$$

### Risk Ratio (RR) 
$$\widehat{RR} \,=\, \frac{\hat \theta_{1}}{\hat \theta_{2}} \,=\, log\left(\frac{\hat p_{1}}{\hat p_{2}}\right)\,=\,log(\hat p_{1}) + log(\hat p_{2})$$
Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))$$
then
$$SE(log(\hat{\theta}))\,=f'(\theta)(var(\theta))\;=\;\frac{1}{p}\sqrt{\frac{p(1-p)}{n}}\,=\,\sqrt{\frac{(1-p)}{pn}}$$
We have that
$$SE(log(\widehat{RR}))\,=\, \sqrt{\frac{(1-\hat p_{1})}{\hat p_{1}n_{1}}}\,+\,\sqrt{\frac{(1-\hat p_{2})}{\hat p_{2}n_{2}}}\,=\,\sqrt{\frac{(1-\hat p_{1})}{\hat p_{1}n_{1}}\,+\,\frac{(1-\hat p_{2})}{\hat p_{2}n_{2}}}$$

### Odds Ratio (OR) 
$$\widehat{OR} \,=\, \frac{\hat \theta_{1}}{\hat \theta_{2}} \,=\, log\left(\frac{\hat p_{1}/(1-\hat p_{1})}{\hat p_{2}/(1-\hat p_{2})}\right)\,=\,log\left(\frac{\text{n}_{11}\text{n}_{22}}{\text{n}_{12}\text{n}_{21}}\right)\,$$
Given that
$$\sqrt(n)\left(f(\hat\theta)-f(\theta)\right)\; \rightarrow N(0\,, var(\theta))$$
then
$$SE(log(\hat{\theta}))\,=f'(\theta)(var(\theta))\;=\;\frac{1}{p(1-p)}\sqrt{\frac{p(1-p)}{n}}\,=\,\sqrt{\frac{1}{n}}$$

We have that
$$SE(log(\widehat{OR}))\,=\, \sqrt{\frac{1}{n_{11}}\,+\,\frac{1}{n_{12}}\,+\,\frac{1}{n_{21}}\,+\,\frac{1}{n_{22}}}$$
Finally, using the *Central Limit Theorem* the Wald type 95\% Confidence Intervals for the RD, RR and OR can be estimated as follows:  

$$95\%\text{CI}\,=\,1.96\times\text(SE(\hat\theta))$$

# Empirical example
To illustrate the use of the Delta Method we are going to generate data based on a cancer epidemiology example where we want to estimate the effect of comorbidities (binary indicator) on one-year cancer mortality controlling for the confounding effect of age in a cohort of 1,000 patients in their middle age. We assume that it is an extremely lethal type of cancer (i.e., pancreatic cancer) thus we can expect high one-year mortality rate among younger patients. Age in years was generated as a normal random variable with mean 65 years and standard deviation 5 years. Comorbidities was generated as a binary indicator and as a function of age using a binomial model. Patients$’$ one-year mortality rate was generated as a function of the patients$’$ age and the presence of comorbidities using a binomial distribution. The data generation and models specifications are provide here below: 

```{r, echo=FALSE, warning=FALSE}
# Data generation
library(tidyverse)

generateData <- function(n, seed){
set.seed(seed)
age <- rnorm(n, 65, 5)
cmbd <- rbinom(n, size=1, prob = plogis(1 - 0.05 * age))
Y <- rbinom(n, size=1, prob = plogis(1 - 0.02* age - 0.02 * cmbd))
data.frame(Y, cmbd, age)
}
```

Here we describe the data

```{r}
# Describing the data
data <- generateData(n = 1000, seed = 777) 
str(data)
summarize(
  data,
  Status = mean(Y), 
  Comorbidities = mean(cmbd),
  Age =  mean(age)
  )
```

## Delta Method for a singly univariate parameter

First, we are going to derive the SE for the single probability or risk of death (the univariate case). We compute the risk of death in our sample and its variance as follows:  

```{r}
# Risk of death
p_death = mean(data$Y)
print(p_death)
```

```{r}
# Varianze for the risk of death
 n = nrow(data)
 var_p_death = p_death * (1 - p_death) / n
 print(var_p_death)
```

Now, let be f(x) = p. Then the first derivative of f′(x) = 1. So the variance of the risk of death can be estimated using (4) as: 

$$\text{Var(P(death))}\,=\,1\times\left[\frac{\text{p(1 - p)}}{n}\right].$$
 
This can be implemented in the following R code:
```{r}
dev_p_death = 1
se_risk = sqrt((dev_p_death) * var_p_death)
print(se_risk)
```

To check that our results are consistent with the implementation of the Delta Method function provide by the **msm** R package used for advanced Geographical Analysis [@kavroudakis2015].

```{r}
# install.packages("msm")
library(msm)
se_risk_delta = deltamethod(g = ~ x1, 
                            mean = p_death,         
                            cov  = var_p_death)
print(se_risk_delta)

cat("Are the same se_risk and se_risk_delta?")

ifelse(
  se_risk == se_risk_delta,
  print("Yes")
)
```

## Conditional Odds Ratio (COR): Multivariable Case

Let$'$s now compute the SE for the COR derived from a multivariable logistic regression model. Note that the COR transformation is a function of the regression coefficients from the logistic model. First we estimate the conditional probability of the risk of death for those patients with comorbidities adjusting for age. The model summary is described here below. The probability of death for a cancer patient in our sample with comorbidities compared with a patient without comorbidities and in average with the same age is approximately 40\% higher: 

```{r}
m1 <- glm(Y ~ age + cmbd, data = data, family = binomial)
summary(m1)
b1 <- coef(m1)[3]
cat("One-year mortality risk for patients with comorbidities vs no comorbidities is:") 
exp(b1)
```

We now, can derive the SE for the conditional OR using the formula (4) for the multivariate case. Note that the first derivative for the exponential function is equal to exponential and that to get the covariance of the parameter fitted in the model we use the command "vcov" in R.

```{r}
grad <- exp(b1)
vcov(m1)
vb1 <- vcov(m1)[3,3]
se <- grad %*% vb1 %*% grad
se_cor <- sqrt(se); se_cor
```

Now, we have to check that our results are consistent with the implementation of the Delta Method function provide by the **msm** R package  [@kavroudakis2015]
```{r}
se_cor_delta <- deltamethod(~ exp(x1), b1, vb1); se_cor_delta

cat("Are the same se_cor and se_cor_delta?")

ifelse(
  se_cor == se_cor_delta,
  print("Yes"),print("No")
)
```

## Conditional Risk Ratio (CRR): multivariable case

Let$'$s now compute the SE for the marginal multivariable RR derived from the predicted probabilities of a  multivariable logistic regression model. First we fit the model with the binary indicator of one-year mortality as dependent variable and patients$’$ age and comorbidities as independent variables. Then, from the fitted model and using the **predict** function we derive the probability of death from pancreatic cancer among patients aged 45 years and with comorbidities versus patients aged 75 years old with no comorbidities. Finally, we compute the conditional RR as the ratio between both probabilities. As we can see the risk of death in a population where cancer patients were aged 45 years with comorbidities is approximately 81\% higher than the risk of one-year mortality among cancer patients aged 75 years and with no comorbidities:

```{r}
m2 <- glm(Y ~ age + cmbd, data = data, family = binomial)
p75 <- predict(m2, newdata = data.frame(age = 75, cmbd = 0), type="response")
p45 <- predict(m2, newdata = data.frame(age = 45, cmbd = 1), type="response")
mrr <- p45 / p75;
cat("Conditional Risk Ratio: ", mrr)
```

Let$'$s now to compute the SE for the marginal RR. Note that the relative risk transformation is a function of the regression coefficients. First, we should define the conditional probability in terms of the regression coefficients. In our model, given patients age and comorbidities, the probability of one-year mortality is:
$$\text{P(Y=1|X)}\,=\,\frac{1}{1\,+\,\text{exp}(−\sum_{i=1}^k \beta(X))}$$
Where k is the number of parameters in the model $\beta\,=\,(\beta_{0},\beta_{1},\beta_{2})$. Therefore,
the probabality of one-year mortality for cancer patients aged 45 years with comorbidities is 
$$\text{P(1)(Y = 1|X1 = 45, X3 = 1)}\,=\,\frac{1}{1\,+\,exp(−\beta_{0}\,-\,\beta_{1}\times 45\,-\,\beta_{2}\times 1)},$$
and the probabality of one-year mortality for cancer patients aged 75 years with no comorbidities is 
$$\text{P(2)(Y = 1|X2 = 75, X4 = 0)}\,=\,\frac{1}{1\,+\,exp(−\beta_{0}\,-\,\beta_{1}\times 75\,-\,\beta_{2}\times 0)}.$$
Note that the CRR is a function of the regression coefficients from the logistic model. Thus, now we use the equation in (3) to get: 
$$\text{f(x)}\,=\,\frac{\frac{1}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2} x3)}}{\frac{1}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2}x4)}},$$
which simplifies to:
$$\text{f(x)}\,=\,\frac{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4)}{1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2}x3)}.$$
We now need to solve the partial derivatives for $f'$ but one can use the online open source available software "Wolfram alpha: https://www.wolframalpha.com/" to readily get the results for $f'$ and then apply the formula (3). Using the product and chain rules, we obtain the following partial derivatives:
$$\frac{df}{d\beta_{0}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times \text{p}(1\,–\,\text{p}),$$
then,
$$\frac{df}{d\beta_{1}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x2 \times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x1 \times \text{p}(1\,–\,\text{p}),$$
and, 
$$\frac{df}{d\beta_{2}}\,=\,\text{−exp}(−\beta_{0}\,-\,\beta_{1}x2\,-\,\beta_{2} x4))\times x4 \times \text{p}\,+\,(1\,+\,\text{exp}(−\beta_{0}\,-\,\beta_{1}x3\,-\,\beta_{2} x4))\times x3 \times \text{p}(1\,–\,\text{p})$$
where p is 
$$\text{P(Y=1|X1,X2)}\,=\,\frac{1}{1\,+\text{exp}(−\beta_{0}\,-\,\beta_{1}x1\,-\,\beta_{2}x3)},$$
i.e., the probability of one-year mortality for cancer patients aged 45 years with comorbidities. 

Let’s calculate our partial derivative in R as follows:

```{r}
x1 <- 45
x2 <- 75
x3 <- 1
x4 <- 0
b0 <- coef(m2)[1]
b1 <- coef(m2)[2]
b2 <- coef(m2)[3]
e1 <- exp(-b0 - 45*b1 - 1*b2)
e2 <- exp(-b0 - 75*b1 - 0*b2)
p1 <- 1 / (1 + e1)
p2 <- 1 / (1 + e2)
dfdb0 <- -e2*p1 + (1 + e2)*p1*(1 - p1)
dfdb1 <- -x2*e2*p1 + (1 + e2)*x1*p1*(1 - p1)
dfdb2 <- -x4*e2*p1 + (1 + e2)*x3*p1*(1 - p1)
grad <- c(dfdb0, dfdb1, dfdb2)
vG <- t(grad) %*% vcov(m2) %*% (grad)
se_crr <- c(sqrt(vG));se_crr
```

Now, let$'$s again to check if our results are consistent with the implementation of the Delta Method function provide by the **msm** R package [@kavroudakis2015]. We obtain the same results for the SE of the crr computed before (0.3653979)

```{r}
se_crr_delta <- deltamethod( ~(1 + exp(-x1 -75*x2 -0*x3)) / (1 + exp(-x1 -45*x2 -1*x3)), 
             c(b0, b1, b2), 
             vcov(m2)
             ); se_crr_delta
```
Finally, let$'$s compute the 95\% confidence intervals (CI):
```{r}
lb <- mrr - 1.96*sqrt(vG)
ub <- mrr + 1.96*sqrt(vG)
cat("\n Conditional Risk Rartio (95%CI): ") ; cat(mrr, "(", lb,",", ub,")")
```

## Marginal Causal Risk Ratio for the potential outcomes and based on the AIPTW estimator

Imagine now, that we want to emulate an impossible clinical trial where we would like to estimate the overall marginal one-year risk of death, standardized across all the levels of patients$'$ age. We are going to  contrast one-year mortality risk for a population where all patients have comorbidities versus another population where patients do not have comorbidities. When estimating the marginal causal risk ratio (MCRR) for a binary treatment (or exposure), methods that incorporate propensity scores, the G-computation, or a combination of both, namely double-robust methods, are preferred over naïve regression approaches which are biased under misspecification of a parametric outcome model. The Augmented Inverse Probability of Treatment Weighting (**AIPTW**) estimation is a double-robust two-step procedure with two equations (propensity score and mean outcome equations). Double-robust methods stem from based on semi-parametric theory (i.e., estimation equations) and only require the correct specification of one model. Here below we provide the formula to compute the MCRR: 

$$\text{Marginal Causal RR}^{AIPTW}\,=\,\frac{EY1}{EY0}\,=\,\text{log(EY1)}\,-\,\text{log(EY0)}.$$
Where 
$$\text{EY(1)}\,=\,\frac{1}{n}\sum_{i=1}^{n}\left(\frac{I\left(A_{i}=1\right)}{g_n(1|W_{i})}\right)\left[Y_{i}-\bar{Q}_{n}\left(A_{i},W_{i}\right)\right]+\frac{1}{n}\sum_{i=1}^{n}\bar{Q}_{n}\left(1,\ W_{i}\right),$$
and
$$\text{EY(0)}\,=\,\frac{1}{n}\sum_{i=1}^{n}\left(\frac{I\left(A_{i}=1\right)}{g_n(0|W_{i})}\right)\left[Y_{i}-\bar{Q}_{n}\left(A_{i},W_{i}\right)\right]+\frac{1}{n}\sum_{i=1}^{n}\bar{Q}_{n}\left(0,\ W_{i}\right).$$
Let$'$s use R to estimate the MCRR. Note that the MCRR is a function of other two functions, the marginal predictions of the regression coefficients from the propensity score logistic model and the marginal predictions from the outcome logistic regression model in case of a binary treatment and outcome. 

```{r}
# Step 1 estimation and prediction of the model for the outcome (G-computation)
gm <- glm(Y ~ age + cmbd, data = data, family = binomial(link=logit))
# Prediction for E(Y|A,W), and E(Y|cmbd = 1, age) and, E(Y|cmbd = 0, age)
QAW <- predict(gm, type = "response")
Q1W <- predict(gm, newdata = data.frame(cmbd = 1, age = data[ ,c("age")]), type = "response")
Q0W <- predict(gm, newdata = data.frame(cmbd = 0, age = data[ ,c("age")]), type = "response")
# Step 2 estimation and prediction of the propensity score (ps): E(A|W) or E(cmbd|age)
psm <- glm(cmbd ~ age*age*age, family = binomial, data = data)
gW = predict(psm, type = "response")
gbounds <- function(x,bounds=c(0.01,1)){
  x[x<min(bounds)] <- min(bounds)
  x[x>max(bounds)] <- max(bounds)
  return(x)
}
#gW <- gbounds(gW,bounds=c(0.05,0.975))
# MCRR
EY1 <- mean((data$Y) * (data$Y - Q1W) / gW + Q1W)
EY0 <- mean((1 - data$Y) * (data$Y - Q0W) / (1 - gW) + Q0W)
logMCRR <- log(EY1) - log(EY0) 
MCRR <- exp(logMCRR);MCRR
```
The marginal contrast of a population of patients where all of them have comorbidities versus other where patients do not have comorbidities after standardizing by the levels of patients age for the one-year mortality risk is 21 times higher for patients with comorbidities. However, we would like to get statistical inference for the estimate of the MCRR. Often researchers use the bootstrap procedure to derive 95\% confidence intervals (CI) but computing efficiency is low. However, we can use the functional Delta Method to apply the Central Limit Theorem and derive Wald type 95\% CI for the MCRR. Here we demonstrate how to derive the functional Delta Method based on the estimation of the efficient influence curve for the AIPTW estimator based on the formula (3) [@van2011]. In summary, for observed data $\text{O}_i$, i = 1, ..., n an asymptotically linear estimator $\hat\Psi$ of an estimand $\Psi$, is an estimator that can be represented as follows [@van2011]: 
$$\hat\Psi\,-\,\Psi\;=\;\frac{1}{n}\sum_{i=1}^n \text{D}(\text{O}_{i})\,+\,\text{Op}(\frac{1}{\sqrt(n)})\;\;(4).$$
Where  
$$\text{D}(\text{O}_{i})=f'(\theta)(\hat\theta\,-\,\theta).$$ 

Therefore for the log(MCRR) = log(EY1)-log(EY0), we have the following two partial derivatives:
$$\frac{\partial log(EY1,EY0)}{\partial EY1}\,=\, \frac{1}{EY1}, $$
and,
$$\frac{\partial log(EY0,EY1)}{\partial EY0}\,=\, \frac{1}{EY0}. $$
Let$'$s now call D1 and D0 the two functionals for the potential otucomes EY1 and EY0. Thus, based on $(\hat\theta\,-\,\theta)$ we get [@van2011]:
D1 = $$\frac{1}{n}\sum_{i=1}^{n}\left(\frac{I\left(A_{i}=1\right)}{g_n(1|W_{i})}\right)\left[Y_{i}-\bar{Q}_{n}\left(A_{i},W_{i}\right)\right]+\frac{1}{n}\sum_{i=1}^{n}\bar{Q}_{n}\left(1,\ W_{i}\right)\,-\,\text{E}(Y(1))$$
and,
D0 = $$\frac{1}{n}\sum_{i=1}^{n}\left(\frac{I\left(A_{i}=0\right)}{g_n(0|W_{i})}\right)\left[Y_{i}-\bar{Q}_{n}\left(A_{i},W_{i}\right)\right]+\frac{1}{n}\sum_{i=1}^{n}\bar{Q}_{n}\left(0,W_{i}\right)\,-\, \text{E}(Y(0)).$$
Where
$g_{n}$ is the propensity score for the treatment mechanism (A) and $\bar Q_{n}$ is the estimate of the conditional mean of outcome given treatment and confounders (W); $E(Y|A,W)$. Therefore
D($\text{O}_{i}$) for the log(MCRR)$\,=\,\frac{1}{EY1}D1\,+\,\frac{1}{EY0)}D0.$

```{r}
# Functional Delta Method for statisical inference
D1 <- (data$cmbd) * (data$Y - Q1W) / gW + Q1W - EY1 
D0 <- (1 - data$cmbd) * (data$Y - Q0W) / (1 - gW) + Q0W - EY0
# AIPTW CRR 95%CI
EIC <- ((1 / EY1) * D1) + ((1 / EY0) * D0)
varHat <- var(EIC) / n
CI <- c(exp(logMCRR - 1.96 * sqrt(varHat)), exp(logMCRR + 1.96 * sqrt(varHat))); MCRR; CI
```

Note: In general, when we have near positivity violations i.e., the positivity assumption states that within strata of W (age in our example) every patient had a nonzero probability of receiving either of the two treatment conditions (i.e. 0 <P(A=1|W)<1) the Bootstrap is preferred. 

# The Bootstrap
Finally, we are going to use a more conservative approach for statistical inference (i.e., the bootstrap). Using the Bootstrap the original sample approximates the population from which it was drawn. So resamples from this sample approximate what we would get if we took many samples from the population. The bootstrap distribution of a statistic, based on many resamples, approximates the sampling distribution of the statistic, based on many samples [@efron1982;@efron1983]. For statistical inference, we use the bootstrap standard error of a statistic is the standard deviation of the bootstrap distribution of that statistic. For most statistics, bootstrap distributions approximate the spread, bias, and shape of the
actual sampling distribution. The interval between 2.5 and 97.5 percentiles of the bootstrap distribution of a statistic is a 95\% bootstrap percentile confidence interval for the corresponding parameter [@efron1982;@efron1983].

Now let$'$s use the **boot** R package which provides extensive facilities for bootstrapping and related resampling methods. You can bootstrap a single statistic (e.g. a median), or a vector (e.g., regression weights). We are going to use the nonparametric bootstrapping [@boostrap2003].

```{r, warning=FALSE}
# Can get original estimate, by plugging in indices 1:n
library(boot)
aiptw.w = function(data,indices)
{
    dat=data[indices,]
    gm <- glm(Y ~ age + cmbd, data = dat, family = binomial(link=logit))
    # Prediction for E(Y|A,W), and E(Y|cmbd = 1, age) and, E(Y|cmbd = 0, age)
    Q1W <- predict(gm, newdata = data.frame(cmbd = 1, age = dat[ ,c("age")]), type = "response")
    Q0W <- predict(gm, newdata = data.frame(cmbd = 0, age = dat[ ,c("age")]), type = "response")
    # Step 2 estimation and prediction of the propensity score (ps): E(A|W) or E(cmbd|age)
    psm <- glm(cmbd ~ age, family = binomial, data = dat)
    gW = predict(psm, type = "response")
    # MCRR
    EY1 <- mean((data$Y) * (data$Y - Q1W) / gW + Q1W)
    EY0 <- mean((1 - data$Y) * (data$Y - Q0W) / (1 - gW) + Q0W)
    MCRR <- EY1 / EY0 
}
# Can get original estimate, by plugging in indices 1:n
aiptw.w(data,indices=1:nrow(data))
# Draw 200 bootstrap sample estimates 
boot.out=boot(data,aiptw.w,1000)
# compute confidence intervals using percentile method
boot.ci(boot.out,type="perc",conf=0.95)
```
Note that we got slightly narrower confidence intervals using the delta method compared to the Bootstrap procedure. It is because with the functional delta method in finite samples for causal inference the coverage decreases when there are violations of the positivity violations and it provide more precisse confidence intervals than other approaches such as the Bootastrap [@Dorie_2019]. In our empirical example the bootstrap compared to the delta method provide more conservative confidence intervals. 

# Conclusion
1. The Delta Method is widely used in classical epidemiological methods to derive the standard error (i.e., statistical inference) of functions of the coefficients of the parameters fitted in regression models. In casual inference is largely used because it eases the derivation of Wald type confidence intervals for data-adaptive double-robust estimators.
2. Recently, the study of the behaviour of the delta method for data-adaptive double-robust estimators in finite samples where there are positivity violations has shown that the functional delta method provides less conservative confidence intervals thant the Bootstrap. Simulations have shown that in such situations the coverage is poor [@Dorie_2019]. Therefore, more conservative and robust approaches such as the bootstrap procedure is still a valid and preferred method for statistical inference under violations and near violations of the positivity assumption. 
3. Users wanted to implemeted the bootstrap proceure using Targeted Maximum Likelihood Estimation would like to use the bootstrap TMLE package: https://github.com/wilsoncai1992/TMLEbootstrap

# Session Info 
```{r session-info}
devtools::session_info()
```

# Thank you  
Thank you for participating in this tutorial.  
If you have updates or changes that you would like to make, please send <a href="https://github.com/migariane/DeltaMethodEpi" target="_blank">me</a> a pull request.
Alternatively, if you have any questions, please e-mail me. 
You can cite this repository as:        
Luque-Fernandez MA, (2019). Delta Method in Epidemiology: An Applied and Reproducible Tutorial. GitHub repository, http://migariane.github.io/DeltaMethodEpi.nb.html.    
**Miguel Angel Luque Fernandez**     
**E-mail:** *miguel-angel.luque at lshtm.ac.uk*  
**Twitter** `@WATZILEI`  

# References 

